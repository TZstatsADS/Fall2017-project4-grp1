---
title: "Collaborative Filtering Algorithms"
author: "Jing Zhao (jz2786)"
date: "11/19/2017"
output: pdf_document
---

## Load Data
```{r}
dataset1_train <- read.csv("../data/data_sample/eachmovie_sample/data_train.csv")
dataset1_test <- read.csv("../data/data_sample/eachmovie_sample/data_test.csv")
```

## Convert raw dataset
```{r}
Transformer <- function(data.set){
  columns.data <- sort(unique(data.set$Movie))
  rows.data <- sort(unique(data.set$User))
  Table_ <- matrix(0,nrow = length(rows.data), ncol = length(columns.data))
  for(i in 1:length(columns.data)){
    col.name <- columns.data[i]
    index <- which(data.set$Movie == col.name)
    scores <- data.set[index,4] #Scores
    users <- data.set[index,3] #Users
    index2 <- which(rows.data %in% users)
    Table_[index2,i] = scores
    Table_[!index2,i] = NA
    }
  colnames(Table_) <- columns.data
  rownames(Table_) <- rows.data
  return(Table_)
}
Table_1 <- Transformer(dataset1_train)
Table_2 <- Transformer(dataset1_test)
save(Table_1, file = "movie_train.RData")
save(Table_2, file = "movie_test.RData")
```

## Correlation
```{r}
cal_weight <- function(data,method){
  
  if(method == 'pearson'){
    result <- as.data.frame(cor(t(data),method = 'pearson'))
  }else if(method == 'spearman'){
    result <- as.data.frame(cor(t(data),method = 'spearman'))
  }else if(method == 'vector'){
    result <- as.data.frame(cosine(t(movie_train)))
  }
  
}
pearson_weight <- cal_weight(Table_1,'pearson')
spearman_weight <- cal_weight(Table_1,'spearman')
vector_weight <- cal_weight(Table_1,'vector')
```



## Significance Weighting
```{r}

significance_weight_assign <- function(i, j, mat=Table_1, not_rate = 0 ){
  r_i <- mat[i, ]
  r_j <- mat[j, ]
  n <- length(intersect(which(r_i != 0), which(r_j != 0)))
  if (n >= 50){
    return(1)
  }
  else {
    return(n/50)
  }
}

significance_weight_matrix <- function(mat_dim_1, mat = Table_1){
  mat_weight = matrix(1, nrow=mat_dim_1, ncol=mat_dim_1)
  for (i in 1:mat_dim_1){
    for (j in (i+1):mat_dim_1){
      weight <- significance_weight_assign(i, j, mat=mat)
      mat_weight[i, j] <- weight
      mat_weight[j, i] <- weight
    }
    
  }
  return(mat_weight)
}

# mat_significance_weight <- significance_weight_matrix(dim(Table_1)[1], mat = Table_1)

```

## Variance Weighting

```{r}
find_var <- function(mat=Table_1){
  var_vector <- apply(Table_1, 2, var)
  var_max <- max(var_vector)
  var_min <- min(var_vector)
  v <- (var_vector - var_min)/var_max
  return(v)
}

variance_weight_assign <- function(i, j, v, mat=Table_1){
  r_i <- scale(mat[i, ])
  r_j <- scale(mat[j, ])
  weight <- sum(v*r_i*r_j)/sum(v)
  return(weight)
}

variance_weight_matrix <- function(mat_dim_1, mat = Table_1){
  mat_weight = matrix(1, nrow=mat_dim_1, ncol=mat_dim_1)
  v <- find_var(mat = mat)
  for (i in 1:mat_dim_1){
    print(i)
    print(Sys.time())
    for (j in (i+1):mat_dim_1){
      weight <- variance_weight_assign(i, j, v, mat = Table_1)
      mat_weight[i, j] <- weight
      mat_weight[j, i] <- weight
    }
  }
  return(mat_weight)
}

#mat_variance_weight <- variance_weight_matrix(dim(Table_1)[1], mat = Table_1)

```



## Selecting Neighborhoods - correlation_thresholding
```{r}
thresholding = 0.1
subset.neighbor = floor(thresholding * nrow(try1))
top.neighbors = matrix(0, ncol = subset.neighbor, nrow = nrow(try1))
for(i in 1:nrow(try1)){
  vec1 = try1[i,]
  n = length(vec1)
  index_ = which(vec1 %in% sort(vec1,partial=n-1)[(n-1):(n - subset.neighbor)])
  top.neighbors[i,] = index_[1:subset.neighbor]
}
```

#Prediction
```{r}
#User: index of this user
#try: weights Table
rating.pred <- function(data.set, user, item, try, top.neighbors){
  avg.rating = mean(data.set[user,])
  neighbor.index = top.neighbors[user,]
  neighbor.weights = try[user,neighbor.index]
  neighbor.ratings = data.set[neighbor.index, item]
  neighbor.avg = mean(data.set[neighbor.index, ])
  pred =avg.rating +  sum((neighbor.ratings-neighbor.avg) * neighbor.weights)/sum(neighbor.weights)
  return(pred)
}
```

